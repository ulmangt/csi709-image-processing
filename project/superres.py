import os, sys, scipy, numpy, Image, sophia, operator
from numpy import sum, sqrt, zeros, array

def main_patch_test():
  # load a small section of the boat image
  mat_low = loadImage( 'boatsmall.jpg', (100,150,125,175) ).astype(float)

  # perform nearest neighbor and bilinear interpolation
  # to zoom the image x2
  mat_nn = nearestNeighborZoom( mat_low )
  mat_bi = bilinearZoom( mat_low )

  # show the results
  sophia.a2i( mat_nn ).show()
  sophia.a2i( mat_bi ).show()

  # look for patches of the image similar to the given
  # patch at (100,100,120,120)
  d = scorePatches( mat_low, (0,0,20,20) )
  # create a 5 by 5 grid of the most similar 25 patches
  mat_patch = displayPatches( mat_low, d, 5, 5 )
  sophia.a2if( mat_patch ).show() 

def main_slsqp():
  # load a small section of the boat image
  mat_low = loadImage( 'boatsmall.jpg', (100,150,125,165) ).astype(float)

  width, height = mat_low.shape
  high_size = width * 2 * height * 2

  low_val, high_val, score = patchSimilarityZoom( mat_low )

  def objective_fun( x ):
    val = numpy.dot( high_val, x )
    return numpy.sum( ( low_val - val )**2 )

  #x0 = numpy.ones( high_size ) * 128.

  # nearest neighbor zoom matrix used for initial guess
  mat_nn = nearestNeighborZoom( mat_low )
  x0 = mat_nn.ravel( )
  
  x_bounds = []
  for i in range( high_size ):
    x_bounds.append( ( 0, 255 ) )

  out, fx, its, imode, smode = scipy.optimize.fmin_slsqp( objective_fun, x0, bounds=x_bounds )

  return out, fx, its, imode, smode

def main_lstsq():
  # load a small section of the boat image
  mat_low = loadImage( 'boatsmall.jpg', (100,150,125,165) ).astype(float)

  width, height = mat_low.shape
  high_size = width * 2 * height * 2

  low_val, high_val, score = patchSimilarityZoom( mat_low, size = 5, k=9 )

  high_mat = numpy.linalg.lstsq( high_val, low_val )
  sophia.a2i( high_mat[0].reshape( width*2, height*2 ) ).show()
  return high_mat, low_val, high_val

def main_nnls():
  # load a small section of the boat image
  mat_low = loadImage( 'boatsmall.jpg', (100,150,125,165) ).astype(float)

  width, height = mat_low.shape
  high_size = width * 2 * height * 2

  low_val, high_val, score = patchSimilarityZoom( mat_low )

  b,resid = scipy.optimize.nnls( high_val, low_val )
  sophia.a2i( b.reshape( width*2, height*2 ) ).show()

def main_ampl():
  # load a small section of the boat image
  mat_low = loadImage( 'boatsmall.jpg', (140,140,170,170) ).astype(float)

  width, height = mat_low.shape
  high_size = width * 2 * height * 2

  low_val, high_val, score = patchSimilarityZoom( mat_low, size=3, k=9, sr=2 )
  #low_val, high_val, score = patchSimilarityZoom( mat_low, size=1, k=9, sr=0 )

  writeAmplDataSparse( 'ampl.dat', low_val, high_val, score )

  return low_val, high_val, score


def writeAmplData( file_name, low_val, high_val ):
  """
  Writes an AMPL .dat file to solve the bounded least squares optimization
  problem constructed by patchSimilarityZoom( )
  """

  l,n = high_val.shape

  f = open(file_name, 'w')

  f.write( 'data;\n' )
  f.write( 'param l := %d;\n' % l )
  f.write( 'param n := %d;\n' % n )

  f.write( 'param y :=\n' )
  for i in xrange( l ) :
    f.write( ' %d %d\n' % ( i+1, int( low_val[i] ) ) )

  f.write( ';\n' )

  f.write( 'param x: %s :=\n' %  " ".join( map( str, range( 1, n+1 ) ) ) )
  for i in xrange( l ) :
    f.write( ' %d %s\n' % ( i+1, " ".join( map( amplFormatter, high_val[i] ) ) ) )

  f.write( ';\n' )

  f.close()

def writeAmplDataSparse( file_name, low_val, high_val, score ):

  l,n = high_val.shape

  f = open(file_name, 'w')

  f.write( 'data;\n' )
  f.write( 'param l := %d;\n' % l )
  f.write( 'param n := %d;\n' % n )

  f.write( 'param y :=\n' )
  for i in xrange( l ) :
    f.write( ' %d %d\n' % ( i+1, int( low_val[i] ) ) )

  f.write( ';\n' )

  max_score = numpy.max( score )

  f.write( 'param w :=\n' )
  for i in xrange( l ) :
    f.write( ' %d %f\n' % ( i+1, 1.0 - numpy.sqrt( score[i] / max_score ) ) )

  f.write( ';\n' )


  f.write( 'param x default 0.0 :=\n' )
  for i in xrange( l ) :
    for j in xrange( n ) :
      val = high_val[i,j]
      if val != 0:
        f.write( '%d %d %f\n' % ( i+1, j+1, val ) )

  f.write( ';\n' )

  f.close()

def readAmplData( file_name, size ):
  """
  Reads a result file generated by AMPL and returns a data vector.
  """

  mat = numpy.zeros( size )

  f = open( file_name, 'r' )

  for line in f:
    tokens = line.split()
    # split the line into groups of two, an index and a pixel value
    pairs = [(int(tokens[i]), float(tokens[i+1])) for i in range(0, len(tokens), 2)]
    for index,pixel in pairs:
      mat[index-1] = pixel

  return mat

def amplFormatter( x ):
  if x == 0:
    return str( 0 )
  else:
    return str( x )


def loadImage( path, crop=None ):
  """
  Loads the image at the provided path, crops it, and returns a matrix
  representation of the image converted to grayscale.
  """
  
  if crop:
    return sophia.i2a( Image.open( findFile( path ) ).crop( crop ).convert( 'L' ) )
  else:
    return sophia.i2a( Image.open( findFile( path ) ).convert( 'L' ) )


def nearestNeighborZoom( mat ):
  """
  Zooms image 2x.
  Simply copy each pixel of the low resolution image
  into its four corresponding high resolution image pixels.
  """

  # make four copies of each low resolution pixel
  return mat.repeat( 2, axis=0 ).repeat( 2, axis= 1 );


def bilinearZoom( mat ):
  """
  Zooms image 2x.
  Each high resolution image pixel g(n1,n2) = A0 + A1*n1 + A2*n2 + A3*n1*n2
  The coefficients are a linear function of the surrounding four image values 
  See: Bovik, Alan C. Handbook of Image and Video Processing. 2nd ed. Amsterdam: Elsevier Academic, 2005. 35-37. Print.
  Also See: http://en.wikipedia.org/wiki/Bilinear_interpolation
  """

  mat = nearestNeighborZoom( mat )
  high_mat = zeros( mat.shape )

  for x in xrange( 0, mat.shape[0]-1 ):
    for y in xrange( 0, mat.shape[1]-1 ):

      # name the indices of the four surrounding pixels
      # in the same manner as Bovik in Handbook of Image and Video Processing
      n10 = x
      n20 = y

      n11 = x+1
      n21 = y  

      n12 = x
      n22 = y+1 

      n13 = x+1
      n23 = y+1

      # build and solve the linear system
      A = array( [[ 1, n10, n20, n10*n20 ],
                        [ 1, n11, n21, n11*n21 ],
                        [ 1, n12, n22, n12*n22 ],
                        [ 1, n13, n23, n13*n23 ]] )

      b = array( [ mat[n10,n20], mat[n11,n21], mat[n12,n22], mat[n13,n23] ] ) 

      try:

        x1 = x + 0.5
        y1 = y + 0.5

        coef = numpy.linalg.solve( A, b )
        high_mat[x,y] = coef[0] + coef[1]*x1 + coef[2]*y1 + coef[3]*x1*y1
 
      except numpy.linalg.linalg.LinAlgError as err:
 
        print 'Singular Matrix: ', A

  return high_mat


def patchSimilarityZoom( mat, size=5, k=9, sr=1 ):
  """
  Zooms image 2x.
  Utilizes patch similarity within the single image. For each 5x5 subsection of the image,
  similar patches in other parts of the image are searched for. Those patches are then
  treated as if they are all independent images of the initial patch and are used to
  reconstruct a high resolution version of the original patch. This process is repeated
  across the entire image.
  See: Daniel Glasner, Shai Bagon, and Michal Irani. Super-resolution from a Single Image.
       http://www.wisdom.weizmann.ac.il/~vision/SingleImageSR.html
  """

  # nearest neighbor zoom matrix used for sub pixel shift calculations
  mat_nn = nearestNeighborZoom( mat )

  # get the width and height of the high and low resolution image
  width = mat.shape[1]
  height = mat.shape[0]
  low_size = width * height

  high_width = width*2;
  high_height = height*2
  high_size = high_width * high_height

  # build the linear constraint matrices
  # create an array of low resolution pixel intensities
  low_val = numpy.zeros( low_size*k, float )
  # the similarity score for each constraint, used
  # to calculate global weighting in optimization function
  score = numpy.zeros( low_size*k, float )
  # create a matrix for the high resolution constraints
  # one column for each pixel in the high resolution image
  # and one row for each constraint
  high_val = numpy.zeros( (low_size*k , high_size) , float )

  # loop over pixels in the low resolution image
  index = 0
  for x in xrange( 0, width ):
    print 'row:', x, '/', width
    for y in xrange( 0, height ):

      # create a square gaussian kernel
      # multiple by 2 because the kernel acts
      # on the pixels of the high resolution image
      kernel = createGaussianKernel( x*2, y*2, width*2, height*2, size*2 )

      # calculate the patch bounds (watching for edge conditions)
      target_patch = getPatchFromCoords( x, y, width, height, size )
      x1,y1,x2,y2 = target_patch

      # offset of patch center (usually size/2, size/2 for non-corner cases)
      xoffset = x - x1
      yoffset = y - y1

      # find similar patches
      d = scorePatches( mat, target_patch )  

      # add constraints for the first k similar patches
      for p in d[0:k]:
        patch, weight = p
        px1,py1,px2,py2 = patch

        dx,dy = evaluateSubPixelOffset( mat_nn, target_patch, patch, sr )

        # stick the kernel into the appropriate place in the matrix
        # (given my the patch p) then ravel the matrix into a
        # 1d constraint vector and add it to the other constraints

        # right now these are the same for each k images... optimize?
        constraint = numpy.zeros( ( high_height, high_width ), float )

        constraint[(y1*2+dy):(y2*2+dy),(x1*2+dx):(x2*2+dx)] = kernel
        
        high_val[index] = constraint.ravel( )
        low_val[index] = mat[py1 - yoffset,px1 - xoffset]
        score[index] = weight 

        index = index + 1

  return low_val, high_val, score

def evaluateSubPixelOffset( mat, target_patch, candidate_patch, search_radius ):
  
  if search_radius <= 0 :
    return ( 0, 0 )

  rows, cols = mat.shape

  minOffset = None

  for x in xrange(-search_radius,search_radius+1):
    for y in xrange(-search_radius,search_radius+1):

      tx1 = target_patch[0]*2 + x
      tx2 = target_patch[2]*2 + x 
      ty1 = target_patch[1]*2 + y
      ty2 = target_patch[3]*2 + y

      if ty1 < 0 or ty2 > rows-1 or tx1 < 0 or tx2 > cols-1 :
        continue

      cx1 = candidate_patch[0]*2
      cx2 = cx1 + tx2 - tx1 
      cy1 = candidate_patch[1]*2
      cy2 = cy1 + ty2 - ty1

      tmat = mat[ ty1:ty2, tx1:tx2 ]
      cmat = mat[ cy1:cy2, cx1:cx2 ]

      score = numpy.sum( ( tmat - cmat )**2 )

      if ( minOffset == None or score < minScore ):
        minScore = score
        minOffset = (x, y)

  return minOffset


# size must be odd here (a size in the low rez image)
def getPatchFromCoords( x, y, width, height, size ):
  """
  Given a pixel position, the width and height of the image, and the size
  of the desired patch, returns a tuple with the upper left and lower right
  pixel coordinates (inclusive) of the patch.
  """
  x1 = max( 0, x-size/2 )
  y1 = max( 0, y-size/2 )
  x2 = min( width, x+size/2+1 )
  y2 = min( height, y+size/2+1 )
  return ( x1, y1, x2, y2 )

# size must be even here (a size in the high rez image
# which is double the low res, so if the low rez size
# is odd this should be even)
def createGaussianKernel( x, y, width, height, size ):
  # create a 5x5 gaussian kernel approximation
  # adapted from: http://scipy-lectures.github.com/intro/numpy/numpy.html
  # with x values ranging from -4 to 4
  kernelx = numpy.linspace( -2, 2, size )
  kernel = numpy.exp( -2.0*kernelx**2 )
  # treat the 1d kernel as a column vector times a row vector
  # resulting in a 2d kernel matrix
  kernel = kernel[:,numpy.newaxis] * kernel[numpy.newaxis,:]

  # if we are near the edge of the image, we only need a section of the kernel
  x1 = max( 0, size/2-x-1 )
  y1 = max( 0, size/2-y-1 )
  x2 = min( size, size/2+width-x-1 )
  y2 = min( size, size/2+height-y-1 )
  kernel = kernel[y1:y2,x1:x2]

  # normalize the kernel
  kernel = kernel / numpy.sum( kernel )

  return kernel

def displayPatch( mat, patch ):
  """Display a rectangular subsection of the given image matrix."""
  sophia.a2i( mat[ patch[1]:patch[3], patch[0]:patch[2] ] ).show()

def displayPatches( mat, d, rows, cols ):
  """
  Given an image matrix, a dictionary produced by scorePatches(), and a number of rows and columns.
  Returns a larg image matrix with the best rows*cols patches from d tiled in the image.
  """

  first = d[0]
  width = first[0][2] - first[0][0]
  height = first[0][3] - first[0][1]

  img = zeros( ( cols * width, rows * height ) )

  count = 0
  for x in xrange( cols ):
    for y in xrange( rows ):
      patch = d[count][0]
      img[ x*width:(x+1)*width , y*height:(y+1)*height ] = mat[ patch[1]:patch[3], patch[0]:patch[2] ] 
      count = count + 1

  return img

def scorePatches( mat, patch ):
  """
  Given an image matrix and a four-tuple representing the upper left and lower right corners of a
  sub-section of the image.
  Score all similarly sized sections of the image for their similarity to the given patch and return
  a list of the patch coordinates sorted by similarity score.
  """

  # get the width and height of the search patch
  patch_width = patch[2] - patch[0]
  patch_height = patch[3] - patch[1]

  # get the width and height of the overall image
  image_width = mat.shape[1]
  image_height = mat.shape[0]

  # create a dictionary of patches and their scores
  d = {}

  # iterate through each pixel in the image, creating a candidate patch
  # using that pixel as its upper left corner and score that candidate
  # against the target patch
  for x in xrange( image_width - patch_width ):
    #print x , '/' , image_width - patch_width
    for y in xrange( image_height - patch_height ):
      candidate_patch = (x, y, x+patch_width, y+patch_height)
      score = scorePatch( mat, patch, candidate_patch )
      d[candidate_patch] = score

  return sorted(d.iteritems(), key=operator.itemgetter(1))



def scorePatch( mat, target_patch, candidate_patch ): 
  """
  Given an image matrix and two patches (cropped sections of the image matrix which must be the same size).
  Computes the similarity between the two patches where similarity is defined as the sum of the squared
  differences between pixel intensities of corresponding pixels in the patches.
  """

  tx1,ty1,tx2,ty2 = target_patch
  cx1,cy1,cx2,cy2 = candidate_patch

  # get the width and height of the search patch
  patch_width = tx2 - tx1
  patch_height = ty2 - ty1

  score = 0
  
  target_mat = mat[ty1:ty2,tx1:tx2]
  candidate_mat = mat[cy1:cy2,cx1:cx2]

  return sqrt( sum( ( target_mat - candidate_mat )**2 ) )


# inspired by: http://dotnot.org/blog/archives/2004/03/06/find-a-file-in-pythons-path/
# I wanted a way to automatically find the named image file in the same way python finds imported modules (similar to seaching for resources on the Java classpath)
def findFile( name ):
  for directory in sys.path:
    potential = os.path.join( directory, name )
    if os.path.isfile( potential ):
      return potential

if __name__ == "__main__":
  main()
